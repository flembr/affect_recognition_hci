{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font='serif')\n",
    "%matplotlib inline\n",
    "\n",
    "import os, re, string, itertools\n",
    "\n",
    "from recording import Recording\n",
    "from neural_net import MultiLayerPerceptron\n",
    "from auxiliary import *\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,speaker_id):\n",
    "    X_train = np.stack(df[df.speaker_id != speaker_id].feature_vec.tolist())\n",
    "    y_train = df[df.speaker_id != speaker_id].emotion_label.tolist()\n",
    "    X_test = np.stack(df[df.speaker_id == speaker_id].feature_vec.tolist())\n",
    "    y_test = df[df.speaker_id == speaker_id].emotion_label.tolist()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition 1\n",
    "- Global features (averaged features over time)\n",
    "- Train a single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = dh.build_feature_data(condition=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: float(majority/count) for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_scores_1 = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    scores, cms = [],[]\n",
    "    for speaker_id in tqdm(sorted(set(df_1.speaker_id))):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_1,speaker_id)\n",
    "        y_train = one_hot_encode(y_train, 7)\n",
    "\n",
    "        scl = StandardScaler().fit(X_train)\n",
    "        X_train = scl.transform(X_train)\n",
    "        X_test = scl.transform(X_test)\n",
    "\n",
    "        model = MultiLayerPerceptron([61,96,32,7])\n",
    "        model.fit(X_train,y_train,epochs=100,val_data=(X_test,one_hot_encode(y_test,7)),class_weight=get_class_weights(df_1.emotion_label))\n",
    "        pred = model.predict(X_test)\n",
    "        scores.append(accuracy_score(y_test,pred))\n",
    "        cms.append(confusion_matrix(y_test,model.predict(X_test)))\n",
    "    df_scores_1['score_run_%i'%(i+1)] = scores\n",
    "    df_scores_1['cm_run_%i'%(i+1)] = cms\n",
    "    df_scores_1['speaker'] = sorted(set(df_1.speaker_id))\n",
    "\n",
    "df_scores_1 = df_scores_1.set_index('speaker')\n",
    "df_scores_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition 2\n",
    "- Local features (features per phoneme)\n",
    "- Train a single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_score(predictions,IDs,dh):\n",
    "    pred, labels = [],[]\n",
    "    for x in np.unique(IDs):\n",
    "        p = [predictions[i] for i in range(len(IDs)) if IDs[i] == x] \n",
    "        p = np.mean(p,axis=0)\n",
    "        pred.append(np.argmax(p))\n",
    "        labels.append(dh.emotion_from_ID(x))\n",
    "    return accuracy_score(pred,labels), pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2 = dh.build_feature_data(condition=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_scores_2 = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    scores, cms = [],[]\n",
    "    for speaker_id in tqdm(sorted(set(df_2.speaker_id))):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_2,speaker_id)\n",
    "        y_train = one_hot_encode(y_train, 7)\n",
    "        X_train = np.squeeze(X_train)\n",
    "        X_test = np.squeeze(X_test)\n",
    "\n",
    "        scl = StandardScaler().fit(X_train)\n",
    "        X_train = scl.transform(X_train)\n",
    "        X_test = scl.transform(X_test)\n",
    "\n",
    "        model = MultiLayerPerceptron([61,96,32,7])\n",
    "        model.fit(X_train,y_train,epochs=200,val_data=(X_test,one_hot_encode(y_test,7)),class_weight=get_class_weights(df_2.emotion_label))\n",
    "\n",
    "        score,predictions,labels = aggregate_score(model.predict_proba(X_test).tolist(),\n",
    "                                            df_2[df_2.speaker_id == speaker_id].ID.tolist(),\n",
    "                                            dh)\n",
    "        scores.append(score)\n",
    "        cms.append(confusion_matrix(labels,predictions))\n",
    "        keras.backend.clear_session()\n",
    "    df_scores_2['score_run_%i'%(i+1)] = scores\n",
    "    df_scores_2['cm_run_%i'%(i+1)] = cms\n",
    "    df_scores_2['speaker'] = sorted(set(df_2.speaker_id))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "    \n",
    "df_scores_2 = df_scores_2.set_index('speaker')\n",
    "df_scores_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition 3\n",
    "- Local features (features per phoneme)\n",
    "- Train one classifier per phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_phonemes = list(''.join([string.ascii_letters,string.digits,'@']))\n",
    "df_3 = df_2[df_2.phoneme.isin(valid_phonemes)]\n",
    "common_phonemes = {phoneme: count for phoneme,count in Counter(df_3.phoneme).most_common(6)}\n",
    "df_3 = df_3[df_3.phoneme.isin(common_phonemes)]\n",
    "common_phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_scores_3 = pd.DataFrame()\n",
    "phoneme_dict = {}\n",
    "for i in range(5):\n",
    "    scores, cms = [],[]\n",
    "    phoneme_dict['run_%i'%i] = {}\n",
    "    for speaker_id in tqdm(sorted(set(df_3.speaker_id))):\n",
    "        df_train = df_3[df_3.speaker_id != speaker_id]\n",
    "        df_test = df_3[df_3.speaker_id == speaker_id]\n",
    "        scl = StandardScaler().fit(np.squeeze(np.stack(df_train.feature_vec.tolist())))\n",
    "\n",
    "        model_dict = {}\n",
    "        phoneme_dict['run_%i'%i]['speaker_%s'%speaker_id] = {}\n",
    "        for phoneme in common_phonemes:\n",
    "            model = MultiLayerPerceptron([61,96,32,7])\n",
    "\n",
    "            tmp_train = df_train[df_train.phoneme == phoneme]\n",
    "            X_train = np.squeeze(np.stack(tmp_train.feature_vec.tolist()))\n",
    "            y_train = one_hot_encode(tmp_train.emotion_label.tolist(),7)\n",
    "            tmp = df_test[df_test.phoneme == phoneme]\n",
    "            X_test = np.squeeze(np.stack(tmp.feature_vec.tolist()))\n",
    "            y_test = tmp.emotion_label.tolist()\n",
    "\n",
    "            X_train = scl.transform(X_train)\n",
    "            X_test = scl.transform(X_test)\n",
    "\n",
    "            model.fit(X_train,y_train,epochs=200,val_data=(X_test,one_hot_encode(y_test,7)),class_weight=get_class_weights(tmp_train.emotion_label))\n",
    "            model_dict[phoneme] = model\n",
    "            \n",
    "            # evaluate only this phoneme\n",
    "            ph_pred = [model_dict[row.phoneme].predict_proba(scl.transform(row.feature_vec.reshape(1,-1))) \n",
    "                       for _,row in tmp.iterrows()]\n",
    "            score,predictions,labels = aggregate_score(ph_pred,\n",
    "                                                   tmp.ID.tolist(),\n",
    "                                                   dh)\n",
    "            phoneme_dict['run_%i'%i]['speaker_%s'%speaker_id][phoneme] = score\n",
    "\n",
    "        predictions = [model_dict[row.phoneme].predict_proba(scl.transform(row.feature_vec.reshape(1,-1))) \n",
    "                       for _,row in df_test.iterrows()]\n",
    "\n",
    "        score,predictions,labels = aggregate_score(predictions,\n",
    "                                                   df_test.ID.tolist(),\n",
    "                                                   dh)\n",
    "\n",
    "        scores.append(score)\n",
    "        cms.append(confusion_matrix(labels,predictions))\n",
    "        keras.backend.clear_session()\n",
    "    df_scores_3['score_run_%i'%(i+1)] = scores\n",
    "    df_scores_3['cm_run_%i'%(i+1)] = cms\n",
    "    df_scores_3['speaker'] = sorted(set(df_3.speaker_id))\n",
    "\n",
    "df_scores_3 = df_scores_3.set_index('speaker')\n",
    "df_scores_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores_1[['score_run_%i'%(i+1) for i in range(5)]].to_csv('results/scores_1.csv')\n",
    "# df_scores_2[['score_run_%i'%(i+1) for i in range(5)]].to_csv('results/scores_2.csv')\n",
    "df_scores_3[['score_run_%i'%(i+1) for i in range(5)]].to_csv('results/scores_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('results/cms_1.pkl','wb') as f:\n",
    "    pickle.dump(df_scores_1[['cm_run_%i'%(i+1) for i in range(5)]].to_dict(),f)\n",
    "# with open('results/cms_2.pkl','wb') as f:\n",
    "#     pickle.dump(df_scores_2[['cm_run_%i'%(i+1) for i in range(5)]].to_dict(),f)\n",
    "with open('results/cms_3.pkl','wb') as f:\n",
    "    pickle.dump(df_scores_3[['cm_run_%i'%(i+1) for i in range(5)]].to_dict(),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance by phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i,k in enumerate(phoneme_dict):\n",
    "    df = pd.concat([df,pd.DataFrame(phoneme_dict[k]).T])\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(16,6),dpi=200)\n",
    "sns.boxplot(x='Phoneme',y='Accuracy',whis=2,data=pd.melt(df,id_vars='index',var_name='Phoneme',value_name='Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
